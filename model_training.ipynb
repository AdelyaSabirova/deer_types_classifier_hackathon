{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import ImageEnhance, ImageOps, Image\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import PIL\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "# Аугментации данных\n",
    "class NightTransform:\n",
    "    def __call__(self, img):\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(0.3)  # Темнее\n",
    "        return img\n",
    "\n",
    "class BlackWhiteTransform:\n",
    "    def __call__(self, img):\n",
    "        img = ImageOps.grayscale(img)  # Черно-белое\n",
    "        img = img.convert(\"RGB\")  # Преобразуем в 3 канала\n",
    "        return img\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.Lambda(lambda img: BlackWhiteTransform()(img) if np.random.rand() < 0.2 else img),  # Применяем с вероятностью 20%\n",
    "    transforms.Lambda(lambda img: NightTransform()(img) if np.random.rand() < 0.2 else img),  # Применяем с вероятностью 20%\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Функция для фильтрации файлов\n",
    "def is_image_file(filename):\n",
    "    return any(filename.lower().endswith(extension) for extension in ['.jpeg', '.jpg', '.png'])\n",
    "\n",
    "# Кастомный класс Dataset для обработки ошибок чтения изображений\n",
    "class CustomImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return super(CustomImageFolder, self).__getitem__(index)\n",
    "        except (PIL.UnidentifiedImageError, OSError):\n",
    "            print(f\"Corrupted image detected at index {index}. Skipping.\")\n",
    "            return self.__getitem__((index + 1) % len(self))\n",
    "\n",
    "# Загрузка данных\n",
    "data_dir = 'train_dataset'\n",
    "batch_size = 32\n",
    "\n",
    "# Использование is_valid_file для фильтрации изображений\n",
    "full_dataset = CustomImageFolder(root=data_dir, transform=transform_train, is_valid_file=is_image_file)\n",
    "\n",
    "# Деление данных на тренировочные и валидационные\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Применение различных трансформаций к валидационному набору\n",
    "train_dataset.dataset.transform = transform_train\n",
    "val_dataset.dataset.transform = transform_val\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Определение модели\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "weights = EfficientNet_B0_Weights.DEFAULT\n",
    "model = efficientnet_b0(weights=weights)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 3)  # 3 класса\n",
    "model = model.to(device)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Функции обучения и валидации\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=10):\n",
    "    best_f1 = 0.0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Тренировка\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc.item())\n",
    "\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "        epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        val_losses.append(epoch_loss)\n",
    "        val_accs.append(epoch_acc.item())\n",
    "\n",
    "        print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {epoch_f1:.4f}')\n",
    "\n",
    "        if epoch_f1 > best_f1:\n",
    "            best_f1 = epoch_f1\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "    print(f'Best val F1: {best_f1:.4f}')\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}% F1: {f1:.4f}')\n",
    "\n",
    "# Функция для отрисовки графиков\n",
    "def plot_metrics(train_losses, val_losses, train_accs, val_accs):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accs, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_accs, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Обучение модели\n",
    "train_losses, val_losses, train_accs, val_accs = train_model(model, criterion, optimizer, train_loader, val_loader, device, num_epochs=10)\n",
    "\n",
    "# Отрисовка метрик\n",
    "plot_metrics(train_losses, val_losses, train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и оценка лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pth'))\n",
    "evaluate_model(model, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация предиктов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b0\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Функция для отображения изображения\n",
    "def imshow(image, title=None):\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # Пауза, чтобы графики обновлялись\n",
    "\n",
    "# Функция для преобразования индекса класса в строку с именем класса\n",
    "def index_to_class_str(index, dataset):\n",
    "    return dataset.classes[index]\n",
    "\n",
    "# Инициализация модели EfficientNet-B0\n",
    "model = efficientnet_b0(weights=None)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 3)  # 3 класса\n",
    "\n",
    "# Загрузка весов лучшей модели\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Определение устройства (GPU или CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Преобразования данных (без преобразований)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Увеличить размер на 224 пикселей\n",
    "    transforms.CenterCrop(224)\n",
    "])\n",
    "\n",
    "# Путь к изображению\n",
    "image_path = \"data_to_check_streamlit\"\n",
    "\n",
    "# Загрузка изображения и его отображение без преобразований\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "imshow(image, title=\"Original Image\")\n",
    "\n",
    "# Преобразование изображения для подачи на вход модели\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0).to(device)\n",
    "\n",
    "# Получение предсказаний модели\n",
    "outputs = model(image)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "predicted_class = preds.item()\n",
    "\n",
    "# Вывод предсказанного класса\n",
    "print(f\"Predicted class: {index_to_class_str(predicted_class, val_dataset)}\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
